{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# make sure the current folder (code/) is on sys.path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "import importlib, movie_lists\n",
    "importlib.reload(movie_lists)\n",
    "\n",
    "from movie_lists import (\n",
    "    MARVEL_MCU_FILMS, DC_FILMS, STAR_WARS_FILMS, FAST_FURIOUS_FILMS, \n",
    "    WIZARDING_WORLD_FILMS, ALL_LIVE_ACTION_REMAKES,\n",
    "    MEDIA_ADAPTATIONS, ALL_SUPERHERO_FILMS,\n",
    "    REMAKE_PATTERNS, REMAKE_TITLE_INDICATORS,\n",
    "    SUPERHERO_EXCLUSIONS,\n",
    "    FRANCHISE_SEQUELS,\n",
    "    normalize_domestic_titles\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Applied 1 title corrections\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/dataset_domestic_lifetime_merged.csv\")\n",
    "if 'title' in df.columns:\n",
    "    df['title'] = df['title'].fillna('').astype(str)\n",
    "if 'genre_names' in df.columns:\n",
    "    df['genre_names'] = df['genre_names'].fillna('').astype(str)\n",
    "else:\n",
    "    df['genre_names'] = ''\n",
    "\n",
    "df = normalize_domestic_titles(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Highest Grossing Movies since 2010 (US Domestic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "release_year",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "lifetime_domestic",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c09d222c-2ff3-446d-8bbc-782135884e79",
       "rows": [
        [
         "0",
         "Star Wars: The Force Awakens",
         "2015",
         "936662225.0"
        ],
        [
         "1",
         "Avengers: Endgame",
         "2019",
         "858373000.0"
        ],
        [
         "2",
         "Spider-Man: No Way Home",
         "2021",
         "814866759.0"
        ],
        [
         "3",
         "Top Gun: Maverick",
         "2022",
         "718732821.0"
        ],
        [
         "4",
         "Black Panther",
         "2018",
         "700426566.0"
        ],
        [
         "5",
         "Avatar: The Way of Water",
         "2022",
         "684075767.0"
        ],
        [
         "6",
         "Avengers: Infinity War",
         "2018",
         "678815482.0"
        ],
        [
         "7",
         "Jurassic World",
         "2015",
         "653406625.0"
        ],
        [
         "8",
         "Inside Out 2",
         "2024",
         "652980194.0"
        ],
        [
         "9",
         "Deadpool & Wolverine",
         "2024",
         "636745858.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>lifetime_domestic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>2015</td>\n",
       "      <td>936662225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2019</td>\n",
       "      <td>858373000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>2021</td>\n",
       "      <td>814866759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>2022</td>\n",
       "      <td>718732821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>700426566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avatar: The Way of Water</td>\n",
       "      <td>2022</td>\n",
       "      <td>684075767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>678815482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>2015</td>\n",
       "      <td>653406625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inside Out 2</td>\n",
       "      <td>2024</td>\n",
       "      <td>652980194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deadpool &amp; Wolverine</td>\n",
       "      <td>2024</td>\n",
       "      <td>636745858.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  release_year  lifetime_domestic\n",
       "0  Star Wars: The Force Awakens          2015        936662225.0\n",
       "1             Avengers: Endgame          2019        858373000.0\n",
       "2       Spider-Man: No Way Home          2021        814866759.0\n",
       "3             Top Gun: Maverick          2022        718732821.0\n",
       "4                 Black Panther          2018        700426566.0\n",
       "5      Avatar: The Way of Water          2022        684075767.0\n",
       "6        Avengers: Infinity War          2018        678815482.0\n",
       "7                Jurassic World          2015        653406625.0\n",
       "8                  Inside Out 2          2024        652980194.0\n",
       "9          Deadpool & Wolverine          2024        636745858.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nlargest(10, \"revenue_domestic\")[[\"title\",\"release_year\",\"revenue_domestic\"]].rename(columns={\"revenue_domestic\":\"lifetime_domestic\"}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'backdrop_path', 'genre_ids', 'id', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'poster_path',\n",
       "       'release_date', 'title', 'video', 'vote_average', 'vote_count',\n",
       "       'production_countries', 'release_year', 'genres', 'title_normalized',\n",
       "       'domestic_revenue', 'rank', 'distributor', 'revenue_domestic',\n",
       "       'revenue', 'genre_names'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Country Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Examining production_countries column structure:\n",
      "Sample entries:\n",
      "  Row 0: [{'iso_3166_1': 'US', 'name': 'United States of America'}] (type: <class 'str'>)\n",
      "  Row 1: [{'iso_3166_1': 'US', 'name': 'United States of America'}] (type: <class 'str'>)\n",
      "  Row 2: [{'iso_3166_1': 'US', 'name': 'United States of America'}] (type: <class 'str'>)\n",
      "  Row 3: [{'iso_3166_1': 'US', 'name': 'United States of America'}] (type: <class 'str'>)\n",
      "  Row 4: [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}, {'iso_3166_1': 'US', 'name': 'United States of America'}] (type: <class 'str'>)\n",
      "\n",
      "‚úÖ Added origin-country flags to dataset\n",
      "\n",
      "Production country distribution:\n",
      "  US origin: 1930 (82.5%)\n",
      "  UK/Ireland origin: 382 (16.3%)\n",
      "  Canada origin: 162 (6.9%)\n",
      "  US/UK/CA origin: 2021 (86.4%)\n",
      "\n",
      "Sample of extracted country codes:\n",
      "                                          title production_country_codes  is_origin_usa  is_origin_uk_ie\n",
      "0                                   Toy Story 3                     [US]              1                0\n",
      "1                           Alice in Wonderland                     [US]              1                0\n",
      "2                                    Iron Man 2                     [US]              1                0\n",
      "3                    The Twilight Saga: Eclipse                     [US]              1                0\n",
      "4  Harry Potter and the Deathly Hallows: Part 1                 [GB, US]              1                1\n",
      "5                                     Inception                     [US]              1                0\n",
      "6                                 Despicable Me                     [US]              1                0\n",
      "7                           Shrek Forever After                     [US]              1                0\n",
      "8                      How to Train Your Dragon                     [US]              1                0\n",
      "9                                       Tangled                     [US]              1                0\n"
     ]
    }
   ],
   "source": [
    "# Expand production country info into boolean flags\n",
    "def extract_country_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract production country boolean flags from production_countries column.\n",
    "    This function processes the TMDb production_countries data to create\n",
    "    origin flags for different regions.\n",
    "    \"\"\"\n",
    "    import ast\n",
    "    \n",
    "    if 'production_countries' not in df.columns:\n",
    "        df['production_countries'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    def _normalize_codes(entry):\n",
    "        if pd.isna(entry) or entry == '' or entry == '[]':\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Handle string representation of list of dicts\n",
    "            if isinstance(entry, str):\n",
    "                # Try to parse as literal (ast.literal_eval)\n",
    "                try:\n",
    "                    parsed_entry = ast.literal_eval(entry)\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # If that fails, might be malformed - return empty\n",
    "                    return []\n",
    "            else:\n",
    "                parsed_entry = entry\n",
    "            \n",
    "            # Now extract country codes\n",
    "            if isinstance(parsed_entry, list):\n",
    "                codes = []\n",
    "                for item in parsed_entry:\n",
    "                    if isinstance(item, dict) and item.get('iso_3166_1'):\n",
    "                        codes.append(item['iso_3166_1'])\n",
    "                    elif isinstance(item, str):\n",
    "                        codes.append(item)\n",
    "                return list({code for code in codes if code})\n",
    "        except Exception:\n",
    "            # If anything goes wrong, return empty list\n",
    "            return []\n",
    "        \n",
    "        return []\n",
    "\n",
    "    # Extract country codes from production_countries\n",
    "    df['production_country_codes'] = df['production_countries'].apply(_normalize_codes)\n",
    "    \n",
    "    # Create origin flags\n",
    "    df['is_origin_usa'] = df['production_country_codes'].apply(lambda codes: int('US' in codes))\n",
    "    df['is_origin_uk_ie'] = df['production_country_codes'].apply(lambda codes: int(bool({'GB', 'IE'} & set(codes))))\n",
    "    df['is_origin_canada'] = df['production_country_codes'].apply(lambda codes: int('CA' in codes))\n",
    "    df['is_origin_us_uk_ca'] = df['production_country_codes'].apply(\n",
    "        lambda codes: int(bool({'US', 'GB', 'IE', 'CA'} & set(codes)))\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply production country feature engineering\n",
    "if not df.empty:\n",
    "    # First, let's examine the production_countries column structure\n",
    "    print(\"üîç Examining production_countries column structure:\")\n",
    "    print(\"Sample entries:\")\n",
    "    for i, entry in enumerate(df['production_countries'].head(5)):\n",
    "        print(f\"  Row {i}: {entry} (type: {type(entry)})\")\n",
    "    \n",
    "    df = extract_country_flags(df)\n",
    "    print('\\n‚úÖ Added origin-country flags to dataset')\n",
    "    \n",
    "    # Display country flag statistics\n",
    "    print(f\"\\nProduction country distribution:\")\n",
    "    print(f\"  US origin: {df['is_origin_usa'].sum()} ({df['is_origin_usa'].mean()*100:.1f}%)\")\n",
    "    print(f\"  UK/Ireland origin: {df['is_origin_uk_ie'].sum()} ({df['is_origin_uk_ie'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Canada origin: {df['is_origin_canada'].sum()} ({df['is_origin_canada'].mean()*100:.1f}%)\")\n",
    "    print(f\"  US/UK/CA origin: {df['is_origin_us_uk_ca'].sum()} ({df['is_origin_us_uk_ca'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample of extracted country codes\n",
    "    print(f\"\\nSample of extracted country codes:\")\n",
    "    sample_codes = df[['title', 'production_country_codes', 'is_origin_usa', 'is_origin_uk_ie']].head(10)\n",
    "    print(sample_codes.to_string())\n",
    "else:\n",
    "    print('‚ö†Ô∏è Dataset empty; skipping country flag extraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Companies and Language Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "distributor",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d3befc18-3c8c-400d-aa77-c26721112521",
       "rows": [
        [
         "0",
         "Walt Disney Studios Motion Pictures"
        ],
        [
         "1",
         "Walt Disney Studios Motion Pictures"
        ],
        [
         "2",
         "Paramount Pictures"
        ],
        [
         "3",
         "Summit Entertainment"
        ],
        [
         "4",
         "Warner Bros."
        ],
        [
         "5",
         "Warner Bros."
        ],
        [
         "6",
         "Universal Pictures"
        ],
        [
         "7",
         "DreamWorks"
        ],
        [
         "8",
         "DreamWorks"
        ],
        [
         "9",
         "Walt Disney Studios Motion Pictures"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0    Walt Disney Studios Motion Pictures\n",
       "1    Walt Disney Studios Motion Pictures\n",
       "2                     Paramount Pictures\n",
       "3                   Summit Entertainment\n",
       "4                           Warner Bros.\n",
       "5                           Warner Bros.\n",
       "6                     Universal Pictures\n",
       "7                             DreamWorks\n",
       "8                             DreamWorks\n",
       "9    Walt Disney Studios Motion Pictures\n",
       "Name: distributor, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distributor format (our main studio information)\n",
    "df['distributor'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studio counts:\n",
      "Disney: 138\n",
      "Warner Bros: 224\n",
      "Universal: 204\n",
      "Sony: 222\n",
      "Paramount: 123\n",
      "Fox: 177\n",
      "MGM: 31\n",
      "Lionsgate: 155\n",
      "Major studio total: 1274 (54.5%)\n"
     ]
    }
   ],
   "source": [
    "# Studio boolean flags based on distributor\n",
    "df['is_disney'] = df['distributor'].str.contains('Disney|Walt Disney', case=False, na=False).astype(int)\n",
    "df['is_warner_bros'] = df['distributor'].str.contains('Warner Bros', case=False, na=False).astype(int)\n",
    "df['is_universal'] = df['distributor'].str.contains('Universal', case=False, na=False).astype(int)\n",
    "df['is_sony'] = df['distributor'].str.contains('Sony|Columbia|Screen Gems|TriStar', case=False, na=False).astype(int)\n",
    "df['is_paramount'] = df['distributor'].str.contains('Paramount', case=False, na=False).astype(int)\n",
    "df['is_fox'] = df['distributor'].str.contains('Fox|20th Century', case=False, na=False).astype(int)\n",
    "df['is_mgm'] = df['distributor'].str.contains('MGM|United Artists', case=False, na=False).astype(int)\n",
    "df['is_lionsgate'] = df['distributor'].str.contains('Lionsgate', case=False, na=False).astype(int)\n",
    "\n",
    "df['is_major_studio'] = (df['is_disney'] | df['is_warner_bros'] | df['is_universal'] |\n",
    "                         df['is_sony'] | df['is_paramount'] | df['is_fox'] |\n",
    "                         df['is_mgm'] | df['is_lionsgate']).astype(int)\n",
    "\n",
    "print(\"Studio counts:\")\n",
    "print(f\"Disney: {df['is_disney'].sum()}\")\n",
    "print(f\"Warner Bros: {df['is_warner_bros'].sum()}\")\n",
    "print(f\"Universal: {df['is_universal'].sum()}\")\n",
    "print(f\"Sony: {df['is_sony'].sum()}\")\n",
    "print(f\"Paramount: {df['is_paramount'].sum()}\")\n",
    "print(f\"Fox: {df['is_fox'].sum()}\")\n",
    "print(f\"MGM: {df['is_mgm'].sum()}\")\n",
    "print(f\"Lionsgate: {df['is_lionsgate'].sum()}\")\n",
    "print(f\"Major studio total: {df['is_major_studio'].sum()} ({df['is_major_studio'].mean()*100:.1f}%)\")\n",
    "\n",
    "# language\n",
    "df['is_english'] = (df['original_language'].fillna('').str.lower() == 'en').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring genres in the dataset:\n",
      "Total unique genres: 18\n",
      "Total genre entries (including duplicates): 6227\n",
      "\n",
      "All genres sorted by frequency:\n",
      "genre_names\n",
      "Drama              1028\n",
      "Comedy              765\n",
      "Action              703\n",
      "Thriller            613\n",
      "Adventure           528\n",
      "Romance             357\n",
      "Horror              315\n",
      "Science Fiction     309\n",
      "Crime               302\n",
      "Family              293\n",
      "Fantasy             291\n",
      "Animation           225\n",
      "Mystery             190\n",
      "History             152\n",
      "Music                66\n",
      "War                  65\n",
      "Western              23\n",
      "Unknown               2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine genre data (stored as list in genres column)\n",
    "print(\"Exploring genres in the dataset:\")\n",
    "\n",
    "# The genres column contains genre IDs, let's convert them to readable format\n",
    "# TMDb genre ID mappings\n",
    "genre_map = {\n",
    "    '28': 'Action',\n",
    "    '12': 'Adventure',\n",
    "    '16': 'Animation',\n",
    "    '35': 'Comedy',\n",
    "    '80': 'Crime',\n",
    "    '99': 'Documentary',\n",
    "    '18': 'Drama',\n",
    "    '10751': 'Family',\n",
    "    '14': 'Fantasy',\n",
    "    '36': 'History',\n",
    "    '27': 'Horror',\n",
    "    '10402': 'Music',\n",
    "    '9648': 'Mystery',\n",
    "    '10749': 'Romance',\n",
    "    '878': 'Science Fiction',\n",
    "    '10770': 'TV Movie',\n",
    "    '53': 'Thriller',\n",
    "    '10752': 'War',\n",
    "    '37': 'Western'\n",
    "}\n",
    "\n",
    "# Convert genre IDs to names\n",
    "def convert_genre_ids(genre_str):\n",
    "    if pd.isna(genre_str):\n",
    "        return 'Unknown'\n",
    "    genre_names = []\n",
    "    # Remove brackets and split by comma\n",
    "    genre_str = str(genre_str).strip('[]').replace(' ', '')\n",
    "    if genre_str:\n",
    "        genre_ids = genre_str.split(',')\n",
    "        for gid in genre_ids:\n",
    "            gid = gid.strip()\n",
    "            if gid in genre_map:\n",
    "                genre_names.append(genre_map[gid])\n",
    "    return ','.join(genre_names) if genre_names else 'Unknown'\n",
    "\n",
    "df['genre_names'] = df['genres'].apply(convert_genre_ids)\n",
    "\n",
    "# Split and explode genres to get individual genre counts\n",
    "genres_exploded = df['genre_names'].str.split(',').explode().str.strip()\n",
    "unique_genres = genres_exploded.value_counts()\n",
    "\n",
    "print(f\"Total unique genres: {len(unique_genres)}\")\n",
    "print(f\"Total genre entries (including duplicates): {len(genres_exploded)}\")\n",
    "print(\"\\nAll genres sorted by frequency:\")\n",
    "print(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot encoded features for all genres:\n",
      "Created 17 genre features:\n",
      "\n",
      "Genre feature counts:\n",
      "Drama: 1028\n",
      "Comedy: 765\n",
      "Action: 703\n",
      "Thriller: 613\n",
      "Adventure: 528\n",
      "Romance: 357\n",
      "Horror: 315\n",
      "Science Fiction: 309\n",
      "Crime: 302\n",
      "Family: 293\n",
      "Fantasy: 291\n",
      "Animation: 225\n",
      "Mystery: 190\n",
      "History: 152\n",
      "Music: 66\n",
      "War: 65\n",
      "Western: 23\n",
      "\n",
      "Genre columns created: ['genre_drama', 'genre_comedy', 'genre_action', 'genre_thriller', 'genre_adventure', 'genre_romance', 'genre_horror', 'genre_science_fiction', 'genre_crime', 'genre_family']...\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode all genres\n",
    "print(\"Creating one-hot encoded features for all genres:\")\n",
    "\n",
    "# Get all unique genres from converted names\n",
    "genres_exploded = df['genre_names'].str.split(',').explode().str.strip()\n",
    "all_genres = genres_exploded.value_counts().index.tolist()\n",
    "# Remove 'Unknown' if it exists\n",
    "all_genres = [g for g in all_genres if g != 'Unknown']\n",
    "\n",
    "# Create boolean flag for each genre\n",
    "genre_columns = []\n",
    "for genre in all_genres:\n",
    "    col_name = f'genre_{genre.lower().replace(\" \", \"_\").replace(\"-\", \"_\")}'\n",
    "    df[col_name] = df['genre_names'].str.contains(genre, case=False, na=False).astype(int)\n",
    "    genre_columns.append(col_name)\n",
    "\n",
    "print(f\"Created {len(genre_columns)} genre features:\")\n",
    "print(\"\\nGenre feature counts:\")\n",
    "for i, col in enumerate(genre_columns):\n",
    "    count = df[col].sum()\n",
    "    original_genre = all_genres[i]\n",
    "    print(f\"{original_genre}: {count}\")\n",
    "\n",
    "print(f\"\\nGenre columns created: {genre_columns[:10]}...\" if len(genre_columns) > 10 else f\"\\nGenre columns created: {genre_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular genre combinations:\n",
      "Action + Adventure: 293\n",
      "Action + Sci-Fi: 196\n",
      "Comedy + Romance: 164\n",
      "Family + Animation: 175\n"
     ]
    }
   ],
   "source": [
    "# Genre combinations using new one-hot encoded features\n",
    "df['is_action_adventure'] = (df['genre_action'] & df['genre_adventure']).astype(int)\n",
    "df['is_action_sci_fi'] = (df['genre_action'] & df['genre_science_fiction']).astype(int)\n",
    "df['is_comedy_romance'] = (df['genre_comedy'] & df['genre_romance']).astype(int)\n",
    "df['is_family_animation'] = (df['genre_family'] & df['genre_animation']).astype(int)\n",
    "\n",
    "print(\"Popular genre combinations:\")\n",
    "print(f\"Action + Adventure: {df['is_action_adventure'].sum()}\")\n",
    "print(f\"Action + Sci-Fi: {df['is_action_sci_fi'].sum()}\")\n",
    "print(f\"Comedy + Romance: {df['is_comedy_romance'].sum()}\")\n",
    "print(f\"Family + Animation: {df['is_family_animation'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top genres:\n",
      "primary_genre\n",
      "Drama        494\n",
      "Action       440\n",
      "Comedy       361\n",
      "Horror       228\n",
      "Animation    133\n",
      "Adventure    108\n",
      "Thriller     102\n",
      "Family        86\n",
      "Romance       80\n",
      "Crime         79\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average genres per movie: 2.66\n",
      "Max genres in one movie: 7\n"
     ]
    }
   ],
   "source": [
    "# Primary genre and genre count\n",
    "df['primary_genre'] = df['genre_names'].str.split(',').str[0].fillna('Unknown')\n",
    "df['genre_count'] = df['genre_names'].str.count(',').fillna(-1) + 1\n",
    "\n",
    "print(\"Top genres:\")\n",
    "print(df['primary_genre'].value_counts().head(10))\n",
    "print(f\"\\nAverage genres per movie: {df['genre_count'].mean():.2f}\")\n",
    "print(f\"Max genres in one movie: {df['genre_count'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release Month/Season Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating release date features...\n",
      "Release month distribution:\n",
      "release_month_name\n",
      "December     226\n",
      "August       220\n",
      "October      214\n",
      "March        213\n",
      "November     208\n",
      "September    200\n",
      "July         194\n",
      "February     183\n",
      "April        180\n",
      "June         177\n",
      "May          175\n",
      "January      149\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Seasonal distribution:\n",
      "release_season\n",
      "Fall      622\n",
      "Summer    591\n",
      "Spring    568\n",
      "Winter    558\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Special season flags:\n",
      "Summer blockbuster season: 766 (32.7%)\n",
      "Holiday releases: 434 (18.6%)\n",
      "Oscar season: 648 (27.7%)\n"
     ]
    }
   ],
   "source": [
    "# Release Date Features\n",
    "print(\"Creating release date features...\")\n",
    "\n",
    "# Convert release_date to datetime if it's not already\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "\n",
    "# Extract release month\n",
    "df['release_month'] = df['release_date'].dt.month\n",
    "\n",
    "# Create month name for readability\n",
    "df['release_month_name'] = df['release_date'].dt.strftime('%B')\n",
    "\n",
    "# Create seasonal categories\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Fall'\n",
    "\n",
    "df['release_season'] = df['release_month'].apply(get_season)\n",
    "\n",
    "# Create holiday/blockbuster season flags\n",
    "df['is_summer_blockbuster'] = df['release_month'].isin([5, 6, 7, 8]).astype(int)  # May-August\n",
    "df['is_holiday_release'] = df['release_month'].isin([11, 12]).astype(int)  # November-December\n",
    "df['is_oscar_season'] = df['release_month'].isin([10, 11, 12]).astype(int)  # October-December\n",
    "\n",
    "print(f\"Release month distribution:\")\n",
    "month_counts = df['release_month_name'].value_counts()\n",
    "print(month_counts)\n",
    "\n",
    "print(f\"\\nSeasonal distribution:\")\n",
    "seasonal_counts = df['release_season'].value_counts()\n",
    "print(seasonal_counts)\n",
    "\n",
    "print(f\"\\nSpecial season flags:\")\n",
    "print(f\"Summer blockbuster season: {df['is_summer_blockbuster'].sum()} ({df['is_summer_blockbuster'].mean()*100:.1f}%)\")\n",
    "print(f\"Holiday releases: {df['is_holiday_release'].sum()} ({df['is_holiday_release'].mean()*100:.1f}%)\")\n",
    "print(f\"Oscar season: {df['is_oscar_season'].sum()} ({df['is_oscar_season'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Proximity Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating holiday proximity features...\n",
      "Holiday proximity analysis:\n",
      "Movies within 10 days of major holidays: 1165 (49.8%)\n"
     ]
    }
   ],
   "source": [
    "# Holiday Proximity Features\n",
    "print(\"Creating holiday proximity features...\")\n",
    "\n",
    "# Define major US holidays by month/day (approximate, as some vary by year)\n",
    "MAJOR_HOLIDAYS = {\n",
    "    'New Year\\'s Day': (1, 1),\n",
    "    'Martin Luther King Jr. Day': (1, 15),  # 3rd Monday, approximated\n",
    "    'Presidents Day': (2, 15),  # 3rd Monday, approximated\n",
    "    'Memorial Day': (5, 25),  # Last Monday, approximated\n",
    "    'Independence Day': (7, 4),\n",
    "    'Labor Day': (9, 1),  # 1st Monday, approximated\n",
    "    'Columbus Day': (10, 10),  # 2nd Monday, approximated\n",
    "    'Veterans Day': (11, 11),\n",
    "    'Thanksgiving': (11, 25),  # 4th Thursday, approximated\n",
    "    'Christmas': (12, 25),\n",
    "    'New Year\\'s Eve': (12, 31),\n",
    "}\n",
    "\n",
    "# Calculate proximity to holidays\n",
    "def calculate_holiday_proximity(release_date, proximity_days=10):\n",
    "    \"\"\"Check if release date is within proximity_days of any major holiday\"\"\"\n",
    "    month = release_date.month\n",
    "    day = release_date.day\n",
    "    \n",
    "    for holiday_name, (holiday_month, holiday_day) in MAJOR_HOLIDAYS.items():\n",
    "        # Create holiday date for the same year\n",
    "        try:\n",
    "            holiday_date = pd.Timestamp(year=release_date.year, month=holiday_month, day=holiday_day)\n",
    "            \n",
    "            # Calculate days difference\n",
    "            days_diff = abs((release_date - holiday_date).days)\n",
    "            \n",
    "            # Check if within proximity\n",
    "            if days_diff <= proximity_days:\n",
    "                return True, holiday_name, days_diff\n",
    "            \n",
    "            # Also check holiday in previous/next year for year-end releases\n",
    "            if holiday_month in [1, 12]:  # New Year's and Christmas period\n",
    "                if holiday_month == 1:  # Holiday in January, check previous year\n",
    "                    prev_year_holiday = pd.Timestamp(year=release_date.year - 1, month=holiday_month, day=holiday_day)\n",
    "                    days_diff_prev = abs((release_date - prev_year_holiday).days)\n",
    "                    if days_diff_prev <= proximity_days:\n",
    "                        return True, holiday_name, days_diff_prev\n",
    "                \n",
    "                if holiday_month == 12:  # Holiday in December, check next year\n",
    "                    next_year_holiday = pd.Timestamp(year=release_date.year + 1, month=holiday_month, day=holiday_day)\n",
    "                    days_diff_next = abs((release_date - next_year_holiday).days)\n",
    "                    if days_diff_next <= proximity_days:\n",
    "                        return True, holiday_name, days_diff_next\n",
    "                        \n",
    "        except ValueError:\n",
    "            # Skip invalid dates (like Feb 29 in non-leap years)\n",
    "            continue\n",
    "    \n",
    "    return False, None, None\n",
    "\n",
    "# Apply holiday proximity calculation\n",
    "holiday_results = df['release_date'].apply(lambda x: calculate_holiday_proximity(x, 10))\n",
    "\n",
    "# Extract results\n",
    "df['is_holiday_proximity'] = [result[0] for result in holiday_results]\n",
    "df['nearest_holiday'] = [result[1] for result in holiday_results]\n",
    "df['days_to_holiday'] = [result[2] for result in holiday_results]\n",
    "\n",
    "# Convert to proper types\n",
    "df['is_holiday_proximity'] = df['is_holiday_proximity'].astype(int)\n",
    "\n",
    "# Create specific holiday proximity flags\n",
    "df['is_christmas_proximity'] = df['nearest_holiday'].str.contains('Christmas|New Year', na=False).astype(int)\n",
    "df['is_thanksgiving_proximity'] = (df['nearest_holiday'] == 'Thanksgiving').astype(int)\n",
    "df['is_independence_day_proximity'] = (df['nearest_holiday'] == 'Independence Day').astype(int)\n",
    "df['is_memorial_labor_day_proximity'] = df['nearest_holiday'].str.contains('Memorial Day|Labor Day', na=False).astype(int)\n",
    "\n",
    "print(f\"Holiday proximity analysis:\")\n",
    "print(f\"Movies within 10 days of major holidays: {df['is_holiday_proximity'].sum()} ({df['is_holiday_proximity'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating competitive release features...\n",
      "Analyzing competitive releases (major = $50M+ revenue)...\n",
      "Competitive release analysis:\n",
      "Movies with nearby major releases: 2242 (95.9%)\n"
     ]
    }
   ],
   "source": [
    "# Competitive Release Features\n",
    "print(\"Creating competitive release features...\")\n",
    "\n",
    "# Define what constitutes a \"major release\" - we'll use revenue threshold\n",
    "major_release_threshold = 50e6  # $50M+ domestic revenue considered \"major\"\n",
    "\n",
    "# Sort by release date for efficient processing\n",
    "df_sorted = df.sort_values('release_date').reset_index(drop=True)\n",
    "\n",
    "# Initialize competitive release features\n",
    "df_sorted['has_nearby_major_release'] = 0\n",
    "df_sorted['nearby_major_releases_count'] = 0\n",
    "df_sorted['nearby_major_releases_max_revenue'] = 0\n",
    "df_sorted['days_to_nearest_major_release'] = None\n",
    "\n",
    "print(f\"Analyzing competitive releases (major = ${major_release_threshold/1e6:.0f}M+ revenue)...\")\n",
    "\n",
    "# For each movie, check for other major releases within 2 weeks (14 days)\n",
    "for i, row in df_sorted.iterrows():\n",
    "    current_date = row['release_date']\n",
    "    current_revenue = row['revenue_domestic']\n",
    "    \n",
    "    # Define the 2-week window (¬±14 days)\n",
    "    start_window = current_date - pd.Timedelta(days=14)\n",
    "    end_window = current_date + pd.Timedelta(days=14)\n",
    "    \n",
    "    # Find other major releases in the window (excluding current movie)\n",
    "    nearby_releases = df_sorted[\n",
    "        (df_sorted['release_date'] >= start_window) & \n",
    "        (df_sorted['release_date'] <= end_window) &\n",
    "        (df_sorted['revenue_domestic'] >= major_release_threshold) &\n",
    "        (df_sorted.index != i)  # Exclude current movie\n",
    "    ]\n",
    "    \n",
    "    if len(nearby_releases) > 0:\n",
    "        df_sorted.at[i, 'has_nearby_major_release'] = 1\n",
    "        df_sorted.at[i, 'nearby_major_releases_count'] = len(nearby_releases)\n",
    "        df_sorted.at[i, 'nearby_major_releases_max_revenue'] = nearby_releases['revenue_domestic'].max()\n",
    "        \n",
    "        # Find the closest major release by date\n",
    "        date_differences = abs(nearby_releases['release_date'] - current_date).dt.days\n",
    "        df_sorted.at[i, 'days_to_nearest_major_release'] = date_differences.min()\n",
    "\n",
    "# Copy results back to original dataframe (maintaining original order)\n",
    "df = df_sorted.sort_index()\n",
    "\n",
    "# Create intensity categories\n",
    "df['competition_intensity'] = 'Low'\n",
    "df.loc[df['nearby_major_releases_count'] >= 3, 'competition_intensity'] = 'High'\n",
    "df.loc[df['nearby_major_releases_count'].between(1, 2), 'competition_intensity'] = 'Medium'\n",
    "\n",
    "# Create specific competition flags\n",
    "df['has_blockbuster_competition'] = (df['nearby_major_releases_max_revenue'] >= 200e6).astype(int)\n",
    "df['has_immediate_competition'] = (df['days_to_nearest_major_release'] <= 7).astype(int)  # Within 1 week\n",
    "\n",
    "print(f\"Competitive release analysis:\")\n",
    "print(f\"Movies with nearby major releases: {df['has_nearby_major_release'].sum()} ({df['has_nearby_major_release'].mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequel and IP Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequel analysis (excluding documentaries):\n",
      "Title sequel indicators: 377\n",
      "Marvel movies: 36\n",
      "DC movies: 18\n",
      "Star Wars movies: 6\n",
      "Fast & Furious movies: 6\n",
      "Harry Potter movies: 5\n",
      "Franchise sequels: 56\n",
      "Total sequels/franchise: 416 (17.8%)\n",
      "\n",
      "Verifying original movies are not marked as sequels:\n",
      "Marvel original movies (not sequels):\n",
      "  ‚úÖ Thor\n",
      "  ‚úÖ The Avengers\n",
      "  ‚úÖ Guardians of the Galaxy\n",
      "  ‚úÖ Ant-Man\n",
      "  ‚úÖ Doctor Strange\n",
      "Guardians of the Galaxy: is_sequel = 0, is_marvel = 1, is_franchise_sequel = 0\n",
      "Iron Man 2: is_sequel = 1, is_marvel = 1, is_franchise_sequel = 0\n",
      "The Super Mario Galaxy Movie: is_sequel = 1, is_marvel = 0, is_franchise_sequel = 1\n"
     ]
    }
   ],
   "source": [
    "# Sequel detection (excluding documentaries only)\n",
    "sequel_patterns = r'\\b(?:2|3|4|5|6|7|II|III|IV|V|VI|VII|VIII|IX|X|XI|XII|Part|Chapter|Episode|Returns|Rises|Begins)\\b|:'\n",
    "df['is_sequel_title'] = df['title'].str.contains(sequel_patterns, case=False, na=False).astype(int)\n",
    "\n",
    "# Only exclude documentaries (data is already filtered to English movies)\n",
    "not_documentary_mask = ~df['genre_names'].str.contains('Documentary', case=False, na=False)\n",
    "franchise_mask = not_documentary_mask\n",
    "\n",
    "# Marvel films (using imported list)\n",
    "df['is_marvel'] = (df['title'].isin(MARVEL_MCU_FILMS) & franchise_mask).astype(int)\n",
    "\n",
    "# DC films (using imported list) \n",
    "df['is_dc'] = (df['title'].isin(DC_FILMS) & franchise_mask).astype(int)\n",
    "\n",
    "# Star Wars films (exact list + flexible patterns)\n",
    "df['is_star_wars'] = (df['title'].isin(STAR_WARS_FILMS) & franchise_mask).astype(int)\n",
    "for pattern in REMAKE_PATTERNS['star_wars']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False) & franchise_mask\n",
    "    df.loc[matches, 'is_star_wars'] = 1\n",
    "\n",
    "df['is_star_wars'] = df['is_star_wars'].astype(int)\n",
    "\n",
    "# Fast & Furious (exact list + patterns)\n",
    "df['is_fast_furious'] = (df['title'].isin(FAST_FURIOUS_FILMS) & franchise_mask).astype(int)\n",
    "for pattern in REMAKE_PATTERNS['fast_furious']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False) & franchise_mask\n",
    "    df.loc[matches, 'is_fast_furious'] = 1\n",
    "\n",
    "df['is_fast_furious'] = df['is_fast_furious'].astype(int)\n",
    "\n",
    "# Harry Potter / Wizarding World (using imported list + patterns)\n",
    "df['is_harry_potter'] = (df['title'].isin(WIZARDING_WORLD_FILMS) & franchise_mask).astype(int)\n",
    "for pattern in REMAKE_PATTERNS['harry_potter']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False) & franchise_mask\n",
    "    df.loc[matches, 'is_harry_potter'] = 1\n",
    "\n",
    "# Franchise sequels (sequels to established franchises)\n",
    "df['is_franchise_sequel'] = (df['title'].isin(FRANCHISE_SEQUELS) & franchise_mask).astype(int)\n",
    "\n",
    "# FIXED: Combined sequel feature - only include actual sequels, not all franchise movies\n",
    "# Being Marvel/DC doesn't make a movie a sequel - only title indicators and explicit franchise sequels count\n",
    "df['is_sequel'] = (df['is_sequel_title'] | df['is_franchise_sequel'] | \n",
    "                   df['is_star_wars'] | df['is_fast_furious'] | df['is_harry_potter']).astype(int)\n",
    "\n",
    "print(\"Sequel analysis (excluding documentaries):\")\n",
    "print(f\"Title sequel indicators: {df['is_sequel_title'].sum()}\")\n",
    "print(f\"Marvel movies: {df['is_marvel'].sum()}\")\n",
    "print(f\"DC movies: {df['is_dc'].sum()}\")\n",
    "print(f\"Star Wars movies: {df['is_star_wars'].sum()}\")\n",
    "print(f\"Fast & Furious movies: {df['is_fast_furious'].sum()}\")\n",
    "print(f\"Harry Potter movies: {df['is_harry_potter'].sum()}\")\n",
    "print(f\"Franchise sequels: {df['is_franchise_sequel'].sum()}\")\n",
    "print(f\"Total sequels/franchise: {df['is_sequel'].sum()} ({df['is_sequel'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Show some examples to verify the fix\n",
    "print(f\"\\nVerifying original movies are not marked as sequels:\")\n",
    "marvel_originals = df[(df['is_marvel'] == 1) & (df['is_sequel'] == 0)]\n",
    "if not marvel_originals.empty:\n",
    "    print(\"Marvel original movies (not sequels):\")\n",
    "    for title in marvel_originals['title'].head(5):\n",
    "        print(f\"  ‚úÖ {title}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No Marvel original movies found - this may indicate an issue\")\n",
    "\n",
    "# Check specific examples\n",
    "test_titles = ['Guardians of the Galaxy', 'Iron Man', 'Iron Man 2', 'The Super Mario Galaxy Movie']\n",
    "for title in test_titles:\n",
    "    movie = df[df['title'] == title]\n",
    "    if not movie.empty:\n",
    "        row = movie.iloc[0]\n",
    "        print(f\"{title}: is_sequel = {row['is_sequel']}, is_marvel = {row.get('is_marvel', 0)}, is_franchise_sequel = {row.get('is_franchise_sequel', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live-Action Remakes and Adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating remake/adaptation features...\n",
      "Live-action remakes: 23\n",
      "Media adaptations: 55\n",
      "Superhero movies: 80\n",
      "Marvel movies: 36\n",
      "DC movies: 18\n",
      "Star Wars movies: 6\n",
      "Fast & Furious movies: 6\n",
      "Harry Potter movies: 5\n",
      "Remake title indicators: 12\n",
      "Total IP movies: 223 (9.5%)\n",
      "Original content: 2116 (90.5%)\n",
      "\n",
      "Average revenue - IP movies: $229,885,070\n",
      "Average revenue - Original content: $40,577,673\n",
      "IP advantage: 466.5%\n"
     ]
    }
   ],
   "source": [
    "# Create live-action remake and adaptation features (using imported lists)\n",
    "print(\"Creating remake/adaptation features...\")\n",
    "\n",
    "# Live-action remakes (Disney + DreamWorks + others - exact matching first, then patterns)\n",
    "df['is_live_action_remake'] = df['title'].isin(ALL_LIVE_ACTION_REMAKES).astype(int)\n",
    "# Add pattern matching for titles that might be formatted differently\n",
    "for pattern in REMAKE_PATTERNS['live_action_remakes']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False)\n",
    "    df.loc[matches, 'is_live_action_remake'] = 1\n",
    "\n",
    "# Other media adaptations (using imported list + patterns)\n",
    "df['is_adaptation'] = df['title'].isin(MEDIA_ADAPTATIONS).astype(int)\n",
    "for pattern in REMAKE_PATTERNS['other_adaptations']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False)\n",
    "    df.loc[matches, 'is_adaptation'] = 1\n",
    "\n",
    "# Superhero movies (combining all superhero films)\n",
    "df['is_superhero'] = df['title'].isin(ALL_SUPERHERO_FILMS).astype(int)\n",
    "for pattern in REMAKE_PATTERNS['superhero']:\n",
    "    matches = df['title'].str.contains(pattern, case=False, na=False)\n",
    "    df.loc[matches, 'is_superhero'] = 1\n",
    "\n",
    "df.loc[df['title'].isin(SUPERHERO_EXCLUSIONS), 'is_superhero'] = 0\n",
    "\n",
    "# General remake indicators (using imported list)\n",
    "df['has_remake_indicator'] = df['title'].str.contains('|'.join(REMAKE_TITLE_INDICATORS), case=False, na=False).astype(int)\n",
    "\n",
    "# Combined remake/adaptation feature\n",
    "df['is_remake_adaptation'] = (df['is_live_action_remake'] | df['is_adaptation'] | \n",
    "                              df['has_remake_indicator']).astype(int)\n",
    "\n",
    "# Create comprehensive IP movie feature\n",
    "df['is_ip_movie'] = (\n",
    "    df['is_live_action_remake'] |      # Disney/DreamWorks live-action remakes\n",
    "    df['is_adaptation'] |              # Media adaptations (games, toys, TV shows)\n",
    "    df['is_superhero'] |               # All superhero movies (Marvel, DC, others)\n",
    "    df['is_marvel'] |                  # Marvel MCU films\n",
    "    df['is_dc'] |                      # DC films\n",
    "    df['is_star_wars'] |               # Star Wars films\n",
    "    df['is_fast_furious'] |            # Fast & Furious franchise\n",
    "    df['is_harry_potter'] |            # Harry Potter/Wizarding World\n",
    "    df['is_franchise_sequel'] |        # Other catalog sequels/spin-offs\n",
    "    df['has_remake_indicator']         # Movies with remake indicators in title\n",
    ").astype(int)\n",
    "\n",
    "# Ensure binary flags are stored as integers\n",
    "df['is_live_action_remake'] = df['is_live_action_remake'].astype(int)\n",
    "df['is_adaptation'] = df['is_adaptation'].astype(int)\n",
    "df['is_superhero'] = df['is_superhero'].astype(int)\n",
    "df['has_remake_indicator'] = df['has_remake_indicator'].astype(int)\n",
    "df['is_remake_adaptation'] = df['is_remake_adaptation'].astype(int)\n",
    "# Summary\n",
    "print(f\"Live-action remakes: {df['is_live_action_remake'].sum()}\")\n",
    "print(f\"Media adaptations: {df['is_adaptation'].sum()}\")\n",
    "print(f\"Superhero movies: {df['is_superhero'].sum()}\")\n",
    "print(f\"Marvel movies: {df['is_marvel'].sum()}\")\n",
    "print(f\"DC movies: {df['is_dc'].sum()}\")\n",
    "print(f\"Star Wars movies: {df['is_star_wars'].sum()}\")\n",
    "print(f\"Fast & Furious movies: {df['is_fast_furious'].sum()}\")\n",
    "print(f\"Harry Potter movies: {df['is_harry_potter'].sum()}\")\n",
    "print(f\"Remake title indicators: {df['has_remake_indicator'].sum()}\")\n",
    "print(f\"Total IP movies: {df['is_ip_movie'].sum()} ({df['is_ip_movie'].mean()*100:.1f}%)\")\n",
    "original_count = df['is_ip_movie'].eq(0).sum()\n",
    "original_share = df['is_ip_movie'].eq(0).mean()*100\n",
    "print(f\"Original content: {original_count} ({original_share:.1f}%)\")\n",
    "\n",
    "# Performance comparison\n",
    "if df['is_ip_movie'].sum() > 0:\n",
    "    ip_avg = df[df['is_ip_movie'] == 1]['revenue_domestic'].mean()\n",
    "    original_avg = df[df['is_ip_movie'] == 0]['revenue_domestic'].mean()\n",
    "    print(f\"\\nAverage revenue - IP movies: ${ip_avg:,.0f}\")\n",
    "    print(f\"Average revenue - Original content: ${original_avg:,.0f}\")\n",
    "    print(f\"IP advantage: {(ip_avg/original_avg - 1)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year time-based features\n",
    "\n",
    "Years since baseline to catch temporal relationships, streaming era, pandemic era trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating alternative time features...\n",
      "==================================================\n",
      "‚úÖ Alternative time features created:\n",
      "   ‚Ä¢ years_since_baseline: -5 to 11\n",
      "   ‚Ä¢ is_pre_streaming_era: 1440 movies\n",
      "   ‚Ä¢ is_streaming_transition: 248 movies\n",
      "   ‚Ä¢ is_pandemic_year: 152 movies\n",
      "   ‚Ä¢ is_post_pandemic_era: 591 movies\n",
      "\n",
      "üîÆ 2026 Feature Values (safe extrapolation):\n",
      "   ‚Ä¢ years_since_baseline: 11 (linear progression)\n",
      "   ‚Ä¢ is_pre_streaming_era: 0\n",
      "   ‚Ä¢ is_streaming_transition: 0\n",
      "   ‚Ä¢ is_pandemic_year: 0\n",
      "   ‚Ä¢ is_post_pandemic_era: 1 (reasonable assumption)\n"
     ]
    }
   ],
   "source": [
    "# Create alternative time features for safe 2026 extrapolation\n",
    "print(\"Creating alternative time features...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Baseline year for relative time calculation\n",
    "baseline_year = 2015\n",
    "\n",
    "# Alternative Time Feature 1: Relative time progression\n",
    "df['years_since_baseline'] = df['release_year'] - baseline_year\n",
    "\n",
    "# Alternative Time Feature 2: Era-based categorical features\n",
    "df['is_pre_streaming_era'] = (df['release_year'] <= 2018).astype(int)  # Traditional theatrical dominance\n",
    "df['is_streaming_transition'] = (df['release_year'].isin([2019, 2021])).astype(int)  # Market evolution periods  \n",
    "df['is_pandemic_year'] = (df['release_year'].isin([2020, 2021])).astype(int)  # Unique disruption period\n",
    "df['is_post_pandemic_era'] = (df['release_year'] >= 2022).astype(int)  # Recovery/hybrid era\n",
    "\n",
    "print(\"‚úÖ Alternative time features created:\")\n",
    "print(f\"   ‚Ä¢ years_since_baseline: {df['years_since_baseline'].min()} to {df['years_since_baseline'].max()}\")\n",
    "print(f\"   ‚Ä¢ is_pre_streaming_era: {df['is_pre_streaming_era'].sum()} movies\")\n",
    "print(f\"   ‚Ä¢ is_streaming_transition: {df['is_streaming_transition'].sum()} movies\") \n",
    "print(f\"   ‚Ä¢ is_pandemic_year: {df['is_pandemic_year'].sum()} movies\")\n",
    "print(f\"   ‚Ä¢ is_post_pandemic_era: {df['is_post_pandemic_era'].sum()} movies\")\n",
    "\n",
    "print(f\"\\nüîÆ 2026 Feature Values (safe extrapolation):\")\n",
    "print(f\"   ‚Ä¢ years_since_baseline: {2026 - baseline_year} (linear progression)\")\n",
    "print(f\"   ‚Ä¢ is_pre_streaming_era: 0\")\n",
    "print(f\"   ‚Ä¢ is_streaming_transition: 0\") \n",
    "print(f\"   ‚Ä¢ is_pandemic_year: 0\")\n",
    "print(f\"   ‚Ä¢ is_post_pandemic_era: 1 (reasonable assumption)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No title corrections needed\n",
      "üíæ Saving TRAINING datasets (2024, 2025 & 2026 data EXCLUDED to prevent leakage):\n",
      "================================================================================\n",
      "üìö English-only | 2010-2023 (Training) ‚Üí dataset_domestic_processed_english_2010_2026.csv (1,705 rows, years 2010-2023)\n",
      "üìö English-only | 2015-2023 (Training) ‚Üí dataset_domestic_processed_english_2015_2026.csv (1,003 rows, years 2015-2023)\n",
      "üìö Major-studio | 2010-2023 (Training) ‚Üí dataset_domestic_processed_major_2010_2026.csv (1,115 rows, years 2010-2023)\n",
      "üìö Major-studio | 2015-2023 (Training) ‚Üí dataset_domestic_processed_major_2015_2026.csv (643 rows, years 2015-2023)\n",
      "\n",
      "üîÆ Saving FULL dataset (INCLUDING 2024, 2025 & 2026 for testing/evaluation/predictions):\n",
      "================================================================================\n",
      "üé¨ Full dataset ‚Üí dataset_domestic_processed.csv\n",
      "   üìä Total movies: 2,339\n",
      "   üìö Training movies (2010-2023): 1,994\n",
      "   üß™ Test movies (2024): 169\n",
      "   üìà Evaluation movies (2025): 128\n",
      "   üîÆ Prediction movies (2026): 48\n",
      "   üß¨ Features: 101\n",
      "\n",
      "‚úÖ SUCCESS: 2024, 2025 & 2026 data integrated for testing/evaluation/predictions\n",
      "   ‚Ä¢ Training datasets: 2010-2023 only (no data leakage)\n",
      "   ‚Ä¢ 2024 data: available for model testing\n",
      "   ‚Ä¢ 2025 data: available for model evaluation\n",
      "   ‚Ä¢ 2026 data: available for predictions\n",
      "   ‚Ä¢ Proper temporal train/test split maintained\n",
      "\n",
      "ü§ñ Modeling dataset ‚Üí dataset_domestic_processed_modeling.csv (1,994 rows, 2024-2026 excluded)\n"
     ]
    }
   ],
   "source": [
    "# Save different dataset subsets - EXCLUDE 2024, 2025, and 2026 from training datasets\n",
    "from pathlib import Path\n",
    "\n",
    "df = normalize_domestic_titles(df)\n",
    "\n",
    "output_dir = Path('../data')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filter_subset(dataframe, *, start_year=None, end_year=None, language=None, major_only=False, exclude_future_from_training=True):\n",
    "    subset = dataframe.copy()\n",
    "    \n",
    "    # IMPORTANT: Exclude 2024, 2025, and 2026 from training datasets to prevent data leakage\n",
    "    # 2024 = test set, 2025 = evaluation set, 2026 = prediction set\n",
    "    if exclude_future_from_training and 'release_year' in subset.columns:\n",
    "        subset = subset[subset['release_year'] <= 2023]  # Only up to 2023 for training\n",
    "        \n",
    "    if start_year is not None and end_year is not None and 'release_year' in subset.columns:\n",
    "        # For training datasets, adjust end_year to 2023 if it was 2024+ \n",
    "        if end_year >= 2024 and exclude_future_from_training:\n",
    "            end_year = 2023\n",
    "        subset = subset[subset['release_year'].between(start_year, end_year, inclusive='both')]\n",
    "        \n",
    "    if language == 'en' and 'original_language' in subset.columns:\n",
    "        subset = subset[subset['original_language'].fillna('').str.lower() == 'en']\n",
    "    if major_only and 'is_major_studio' in subset.columns:\n",
    "        subset = subset[subset['is_major_studio'].fillna(False).astype(bool)]\n",
    "    return subset\n",
    "\n",
    "# Training datasets (2024, 2025, AND 2026 EXCLUDED)\n",
    "subset_specs = [\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_english_2010_2026.csv',\n",
    "        'description': 'English-only | 2010-2023 (Training)',\n",
    "        'filters': {'start_year': 2010, 'end_year': 2026, 'language': 'en', 'major_only': False, 'exclude_future_from_training': True},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_english_2015_2026.csv',\n",
    "        'description': 'English-only | 2015-2023 (Training)',\n",
    "        'filters': {'start_year': 2015, 'end_year': 2026, 'language': 'en', 'major_only': False, 'exclude_future_from_training': True},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_major_2010_2026.csv',\n",
    "        'description': 'Major-studio | 2010-2023 (Training)',\n",
    "        'filters': {'start_year': 2010, 'end_year': 2026, 'language': None, 'major_only': True, 'exclude_future_from_training': True},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_major_2015_2026.csv',\n",
    "        'description': 'Major-studio | 2015-2023 (Training)', \n",
    "        'filters': {'start_year': 2015, 'end_year': 2026, 'language': None, 'major_only': True, 'exclude_future_from_training': True},\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"üíæ Saving TRAINING datasets (2024, 2025 & 2026 data EXCLUDED to prevent leakage):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for spec in subset_specs:\n",
    "    subset = filter_subset(df, **spec['filters'])\n",
    "    path = output_dir / spec['filename']\n",
    "    subset.to_csv(path, index=False)\n",
    "    if not subset.empty and 'release_year' in subset.columns:\n",
    "        yr_min = int(subset['release_year'].min())\n",
    "        yr_max = int(subset['release_year'].max())\n",
    "        year_span = f\"{yr_min}-{yr_max}\"\n",
    "    else:\n",
    "        year_span = 'n/a'\n",
    "    print(\n",
    "        f\"üìö {spec['description']} ‚Üí {path.name} \"\n",
    "        f\"({len(subset):,} rows, years {year_span})\"\n",
    "    )\n",
    "\n",
    "# Full dataset including 2024, 2025, and 2026 for testing/evaluation/predictions\n",
    "print(f\"\\nüîÆ Saving FULL dataset (INCLUDING 2024, 2025 & 2026 for testing/evaluation/predictions):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "processed_path = output_dir / 'dataset_domestic_processed.csv'\n",
    "df.to_csv(processed_path, index=False)\n",
    "\n",
    "# Count movies by year\n",
    "movies_training = len(df[df['release_year'] <= 2023]) if 'release_year' in df.columns else 0\n",
    "movies_2024 = len(df[df['release_year'] == 2024]) if 'release_year' in df.columns else 0\n",
    "movies_2025 = len(df[df['release_year'] == 2025]) if 'release_year' in df.columns else 0\n",
    "movies_2026 = len(df[df['release_year'] == 2026]) if 'release_year' in df.columns else 0\n",
    "\n",
    "print(f\"üé¨ Full dataset ‚Üí {processed_path.name}\")\n",
    "print(f\"   üìä Total movies: {len(df):,}\")\n",
    "print(f\"   üìö Training movies (2010-2023): {movies_training:,}\")\n",
    "print(f\"   üß™ Test movies (2024): {movies_2024:,}\")\n",
    "print(f\"   üìà Evaluation movies (2025): {movies_2025:,}\")\n",
    "print(f\"   üîÆ Prediction movies (2026): {movies_2026:,}\")\n",
    "print(f\"   üß¨ Features: {df.shape[1]}\")\n",
    "\n",
    "if movies_2024 > 0 or movies_2025 > 0 or movies_2026 > 0:\n",
    "    print(f\"\\n‚úÖ SUCCESS: 2024, 2025 & 2026 data integrated for testing/evaluation/predictions\")\n",
    "    print(f\"   ‚Ä¢ Training datasets: 2010-2023 only (no data leakage)\")\n",
    "    print(f\"   ‚Ä¢ 2024 data: available for model testing\")\n",
    "    print(f\"   ‚Ä¢ 2025 data: available for model evaluation\")\n",
    "    print(f\"   ‚Ä¢ 2026 data: available for predictions\")\n",
    "    print(f\"   ‚Ä¢ Proper temporal train/test split maintained\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: No 2024/2025/2026 movies were added to the dataset\")\n",
    "\n",
    "# Save modeling dataset (training subset with optimal features)\n",
    "modeling_subset = df[df['release_year'] <= 2023].copy() if 'release_year' in df.columns else df.copy()\n",
    "modeling_path = output_dir / 'dataset_domestic_processed_modeling.csv'\n",
    "modeling_subset.to_csv(modeling_path, index=False)\n",
    "print(f\"\\nü§ñ Modeling dataset ‚Üí {modeling_path.name} ({len(modeling_subset):,} rows, 2024-2026 excluded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No title corrections needed\n",
      "üíæ Saved subset (English-only | 2010-2026) ‚Üí ../data/dataset_domestic_processed_english_2010_2026.csv (2,009 rows, years 2010-2026)\n",
      "üíæ Saved subset (English-only | 2015-2026) ‚Üí ../data/dataset_domestic_processed_english_2015_2026.csv (1,307 rows, years 2015-2026)\n",
      "üíæ Saved subset (Major-studio | 2010-2026) ‚Üí ../data/dataset_domestic_processed_major_2010_2026.csv (1,274 rows, years 2010-2026)\n",
      "üíæ Saved subset (Major-studio | 2015-2026) ‚Üí ../data/dataset_domestic_processed_major_2015_2026.csv (802 rows, years 2015-2026)\n",
      "‚úÖ Updated processed domestic dataset saved with 101 features\n"
     ]
    }
   ],
   "source": [
    "# Save different dataset subsets that were used for training at various points\n",
    "from pathlib import Path\n",
    "\n",
    "df = normalize_domestic_titles(df)\n",
    "\n",
    "output_dir = Path('../data')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filter_subset(dataframe, *, start_year=None, end_year=None, language=None, major_only=False):\n",
    "    subset = dataframe.copy()\n",
    "    if start_year is not None and end_year is not None and 'release_year' in subset.columns:\n",
    "        subset = subset[subset['release_year'].between(start_year, end_year, inclusive='both')]\n",
    "    if language == 'en' and 'original_language' in subset.columns:\n",
    "        subset = subset[subset['original_language'].fillna('').str.lower() == 'en']\n",
    "    if major_only and 'is_major_studio' in subset.columns:\n",
    "        subset = subset[subset['is_major_studio'].fillna(False).astype(bool)]\n",
    "    return subset\n",
    "\n",
    "subset_specs = [\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_english_2010_2026.csv',\n",
    "        'description': 'English-only | 2010-2026',\n",
    "        'filters': {'start_year': 2010, 'end_year': 2026, 'language': 'en', 'major_only': False},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_english_2015_2026.csv',\n",
    "        'description': 'English-only | 2015-2026',\n",
    "        'filters': {'start_year': 2015, 'end_year': 2026, 'language': 'en', 'major_only': False},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_major_2010_2026.csv',\n",
    "        'description': 'Major-studio | 2010-2026',\n",
    "        'filters': {'start_year': 2010, 'end_year': 2026, 'language': None, 'major_only': True},\n",
    "    },\n",
    "    {\n",
    "        'filename': 'dataset_domestic_processed_major_2015_2026.csv',\n",
    "        'description': 'Major-studio | 2015-2026',\n",
    "        'filters': {'start_year': 2015, 'end_year': 2026, 'language': None, 'major_only': True},\n",
    "    },\n",
    "]\n",
    "\n",
    "for spec in subset_specs:\n",
    "    subset = filter_subset(df, **spec['filters'])\n",
    "    path = output_dir / spec['filename']\n",
    "    subset.to_csv(path, index=False)\n",
    "    if not subset.empty and 'release_year' in subset.columns:\n",
    "        yr_min = int(subset['release_year'].min())\n",
    "        yr_max = int(subset['release_year'].max())\n",
    "        year_span = f\"{yr_min}-{yr_max}\"\n",
    "    else:\n",
    "        year_span = 'n/a'\n",
    "    print(\n",
    "        f\"üíæ Saved subset ({spec['description']}) ‚Üí {path} \"\n",
    "        f\"({len(subset):,} rows, years {year_span})\"\n",
    "    )\n",
    "\n",
    "processed_path = output_dir / 'dataset_domestic_processed.csv'\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"‚úÖ Updated processed domestic dataset saved with {df.shape[1]} features\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "box_office",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
