{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# GPT-4o Feature Validation for Box Office Dataset\n",
    "\n",
    "This notebook validates and corrects movie features using GPT-4o's knowledge. It sends movie information to the model and asks it to verify the accuracy of our engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API key loaded from config.json\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OpenAI API setup\n",
    "import openai\n",
    "\n",
    "# Load API key from config.json\n",
    "try:\n",
    "    with open('../config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Set OpenAI API key\n",
    "    openai.api_key = config['OPENAI_API_KEY']\n",
    "    os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "\n",
    "    print(\"✅ OpenAI API key loaded from config.json\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ config.json not found. Please create it with your OPENAI_API_KEY\")\n",
    "    print(\"Example config.json structure:\")\n",
    "    print('{\\n  \"OPENAI_API_KEY\": \"your-api-key-here\"\\n}')\n",
    "except KeyError:\n",
    "    print(\"❌ OPENAI_API_KEY not found in config.json\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading config: {e}\")\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Load Dataset and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "xvmxj3gxidh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 2338 movies\n",
      "Years covered: 2010 - 2026\n",
      "Features: 101\n",
      "\n",
      "All 101 columns in the dataset:\n",
      "==================================================\n",
      " 1. adult\n",
      " 2. backdrop_path\n",
      " 3. genre_ids\n",
      " 4. id\n",
      " 5. original_language\n",
      " 6. original_title\n",
      " 7. overview\n",
      " 8. popularity\n",
      " 9. poster_path\n",
      "10. release_date\n",
      "11. title\n",
      "12. video\n",
      "13. vote_average\n",
      "14. vote_count\n",
      "15. production_countries\n",
      "16. release_year\n",
      "17. production_country_codes\n",
      "18. is_origin_usa\n",
      "19. is_origin_uk_ie\n",
      "20. is_origin_canada\n",
      "21. is_origin_us_uk_ca\n",
      "22. genres\n",
      "23. title_normalized\n",
      "24. domestic_revenue\n",
      "25. rank\n",
      "26. distributor\n",
      "27. revenue_domestic\n",
      "28. revenue\n",
      "29. genre_names\n",
      "30. is_disney\n",
      "31. is_warner_bros\n",
      "32. is_universal\n",
      "33. is_sony\n",
      "34. is_paramount\n",
      "35. is_fox\n",
      "36. is_mgm\n",
      "37. is_lionsgate\n",
      "38. is_major_studio\n",
      "39. is_english\n",
      "40. genre_drama\n",
      "41. genre_comedy\n",
      "42. genre_action\n",
      "43. genre_thriller\n",
      "44. genre_adventure\n",
      "45. genre_romance\n",
      "46. genre_horror\n",
      "47. genre_science_fiction\n",
      "48. genre_crime\n",
      "49. genre_family\n",
      "50. genre_fantasy\n",
      "51. genre_animation\n",
      "52. genre_mystery\n",
      "53. genre_history\n",
      "54. genre_music\n",
      "55. genre_war\n",
      "56. genre_western\n",
      "57. is_action_adventure\n",
      "58. is_action_sci_fi\n",
      "59. is_comedy_romance\n",
      "60. is_family_animation\n",
      "61. primary_genre\n",
      "62. genre_count\n",
      "63. release_month\n",
      "64. release_month_name\n",
      "65. release_season\n",
      "66. is_summer_blockbuster\n",
      "67. is_holiday_release\n",
      "68. is_oscar_season\n",
      "69. is_holiday_proximity\n",
      "70. nearest_holiday\n",
      "71. days_to_holiday\n",
      "72. is_christmas_proximity\n",
      "73. is_thanksgiving_proximity\n",
      "74. is_independence_day_proximity\n",
      "75. is_memorial_labor_day_proximity\n",
      "76. has_nearby_major_release\n",
      "77. nearby_major_releases_count\n",
      "78. nearby_major_releases_max_revenue\n",
      "79. days_to_nearest_major_release\n",
      "80. competition_intensity\n",
      "81. has_blockbuster_competition\n",
      "82. has_immediate_competition\n",
      "83. is_sequel_title\n",
      "84. is_marvel\n",
      "85. is_dc\n",
      "86. is_star_wars\n",
      "87. is_fast_furious\n",
      "88. is_harry_potter\n",
      "89. is_franchise_sequel\n",
      "90. is_sequel\n",
      "91. is_live_action_remake\n",
      "92. is_adaptation\n",
      "93. is_superhero\n",
      "94. has_remake_indicator\n",
      "95. is_remake_adaptation\n",
      "96. is_ip_movie\n",
      "97. years_since_baseline\n",
      "98. is_pre_streaming_era\n",
      "99. is_streaming_transition\n",
      "100. is_pandemic_year\n",
      "101. is_post_pandemic_era\n",
      "\n",
      "Sample movies for validation:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "release_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "distributor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_ip_movie",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_adaptation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_marvel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_dc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_superhero",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "55676c46-b02e-4a55-8cd1-e855e33e58dc",
       "rows": [
        [
         "0",
         "Toy Story 3",
         "2010",
         "Walt Disney Studios Motion Pictures",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "Alice in Wonderland",
         "2010",
         "Walt Disney Studios Motion Pictures",
         "1",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "Iron Man 2",
         "2010",
         "Paramount Pictures",
         "1",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "3",
         "The Twilight Saga: Eclipse",
         "2010",
         "Summit Entertainment",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "Harry Potter and the Deathly Hallows: Part 1",
         "2010",
         "Warner Bros.",
         "1",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>distributor</th>\n",
       "      <th>is_ip_movie</th>\n",
       "      <th>is_adaptation</th>\n",
       "      <th>is_marvel</th>\n",
       "      <th>is_dc</th>\n",
       "      <th>is_superhero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>2010</td>\n",
       "      <td>Walt Disney Studios Motion Pictures</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>2010</td>\n",
       "      <td>Walt Disney Studios Motion Pictures</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>2010</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Saga: Eclipse</td>\n",
       "      <td>2010</td>\n",
       "      <td>Summit Entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>2010</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  release_year  \\\n",
       "0                                   Toy Story 3          2010   \n",
       "1                           Alice in Wonderland          2010   \n",
       "2                                    Iron Man 2          2010   \n",
       "3                    The Twilight Saga: Eclipse          2010   \n",
       "4  Harry Potter and the Deathly Hallows: Part 1          2010   \n",
       "\n",
       "                           distributor  is_ip_movie  is_adaptation  is_marvel  \\\n",
       "0  Walt Disney Studios Motion Pictures            0              0          0   \n",
       "1  Walt Disney Studios Motion Pictures            1              0          0   \n",
       "2                   Paramount Pictures            1              0          1   \n",
       "3                 Summit Entertainment            0              0          0   \n",
       "4                         Warner Bros.            1              0          0   \n",
       "\n",
       "   is_dc  is_superhero  \n",
       "0      0             0  \n",
       "1      0             0  \n",
       "2      0             1  \n",
       "3      0             0  \n",
       "4      0             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "df = pd.read_csv('../data/dataset_domestic_processed.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} movies\")\n",
    "print(f\"Years covered: {df['release_year'].min()} - {df['release_year'].max()}\")\n",
    "print(f\"Features: {df.shape[1]}\")\n",
    "\n",
    "# Display all column names\n",
    "print(f\"\\nAll {len(df.columns)} columns in the dataset:\")\n",
    "print(\"=\" * 50)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# Display sample of current feature accuracy for reference\n",
    "print(\"\\nSample movies for validation:\")\n",
    "sample_display = df[['title', 'release_year', 'distributor', 'is_ip_movie', 'is_adaptation', 'is_marvel', 'is_dc', 'is_superhero']].head()\n",
    "display(sample_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03903554",
   "metadata": {},
   "source": [
    "## GPT-4o Validation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation functions defined with ALL 34 specified features\n"
     ]
    }
   ],
   "source": [
    "def create_validation_prompt(movie_data):\n",
    "    \"\"\"\n",
    "    Create a prompt for GPT-4o to validate movie features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract ALL specified features for validation (34 columns total)\n",
    "    feature_dict = {\n",
    "        # Basic movie info\n",
    "        'title': movie_data['title'],\n",
    "        'title_normalized': movie_data['title_normalized'],\n",
    "        'release_year': int(movie_data['release_year']),\n",
    "        \n",
    "        # Production/Origin info\n",
    "        'production_country_codes': str(movie_data['production_country_codes']),\n",
    "        'is_origin_usa': bool(movie_data['is_origin_usa']),\n",
    "        'is_origin_uk_ie': bool(movie_data['is_origin_uk_ie']),\n",
    "        'is_origin_canada': bool(movie_data['is_origin_canada']),\n",
    "        'is_origin_us_uk_ca': bool(movie_data['is_origin_us_uk_ca']),\n",
    "        \n",
    "        # Distribution\n",
    "        'distributor': str(movie_data['distributor']),\n",
    "        \n",
    "        # Studio features (9 total)\n",
    "        'is_disney': bool(movie_data['is_disney']),\n",
    "        'is_warner_bros': bool(movie_data['is_warner_bros']),\n",
    "        'is_universal': bool(movie_data['is_universal']),\n",
    "        'is_sony': bool(movie_data['is_sony']),\n",
    "        'is_paramount': bool(movie_data['is_paramount']),\n",
    "        'is_fox': bool(movie_data['is_fox']),\n",
    "        'is_mgm': bool(movie_data['is_mgm']),\n",
    "        'is_lionsgate': bool(movie_data['is_lionsgate']),\n",
    "        'is_major_studio': bool(movie_data['is_major_studio']),\n",
    "        \n",
    "        # Language\n",
    "        'is_english': bool(movie_data['is_english']),\n",
    "        \n",
    "        # IP and franchise features (15 total)\n",
    "        'is_sequel_title': bool(movie_data['is_sequel_title']),\n",
    "        'is_marvel': bool(movie_data['is_marvel']),\n",
    "        'is_dc': bool(movie_data['is_dc']),\n",
    "        'is_star_wars': bool(movie_data['is_star_wars']),\n",
    "        'is_fast_furious': bool(movie_data['is_fast_furious']),\n",
    "        'is_harry_potter': bool(movie_data['is_harry_potter']),\n",
    "        'is_franchise_sequel': bool(movie_data['is_franchise_sequel']),\n",
    "        'is_sequel': bool(movie_data['is_sequel']),\n",
    "        'is_live_action_remake': bool(movie_data['is_live_action_remake']),\n",
    "        'is_adaptation': bool(movie_data['is_adaptation']),\n",
    "        'is_superhero': bool(movie_data['is_superhero']),\n",
    "        'has_remake_indicator': bool(movie_data['has_remake_indicator']),\n",
    "        'is_remake_adaptation': bool(movie_data['is_remake_adaptation']),\n",
    "        'is_ip_movie': bool(movie_data['is_ip_movie'])\n",
    "    }\n",
    "    \n",
    "    # Convert feature dict to JSON string to avoid f-string nesting issues\n",
    "    feature_json = json.dumps(feature_dict, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a movie expert tasked with validating feature classifications for a box office prediction model. \n",
    "\n",
    "Please review the following movie and its current feature classifications, then provide corrections for any inaccurate features.\n",
    "\n",
    "**Movie Information:**\n",
    "{feature_json}\n",
    "\n",
    "**Feature Definitions:**\n",
    "- title: Original movie title\n",
    "- title_normalized: Cleaned version of the title\n",
    "- release_year: Year the movie was released\n",
    "- production_country_codes: Country codes where movie was produced\n",
    "- is_origin_usa/uk_ie/canada/us_uk_ca: Movie origin country flags\n",
    "- distributor: Studio/company that distributed the movie\n",
    "- Studio flags (is_disney, is_warner_bros, etc.): Which major studio distributed it\n",
    "- is_major_studio: Whether distributed by a major studio (Disney, Warner Bros, Universal, Sony, Paramount, Fox, MGM, Lionsgate)\n",
    "- is_english: Whether the movie is in English language\n",
    "- is_sequel_title: Title contains sequel indicators (2, 3, Part, Chapter, etc.)\n",
    "- is_marvel: Marvel Cinematic Universe or Marvel Comics adaptation\n",
    "- is_dc: DC Comics adaptation\n",
    "- is_star_wars: Part of Star Wars franchise\n",
    "- is_fast_furious: Part of Fast & Furious franchise\n",
    "- is_harry_potter: Part of Harry Potter/Wizarding World\n",
    "- is_franchise_sequel: Sequel/spinoff of an established franchise\n",
    "- is_sequel: Any type of sequel (combines multiple sequel indicators)\n",
    "- is_live_action_remake: Live-action version of animated film or remake of classic\n",
    "- is_adaptation: Adapted from other media (books, games, TV shows, toys, comics, etc.)\n",
    "- is_superhero: Features superheroes as main characters\n",
    "- has_remake_indicator: Title contains remake-related words\n",
    "- is_remake_adaptation: Any type of remake or adaptation\n",
    "- is_ip_movie: Based on existing intellectual property (comprehensive IP flag)\n",
    "\n",
    "**Instructions:**\n",
    "1. Use your knowledge of this specific movie to verify each feature\n",
    "2. Focus on accuracy - only return corrections for features that are definitively wrong\n",
    "3. Pay special attention to:\n",
    "   - Studio/distributor accuracy (which studio actually distributed this movie?)\n",
    "   - IP classification (Marvel, DC, adaptations, remakes, sequels)\n",
    "   - Franchise identification (is this really part of these franchises?)\n",
    "   - Origin country information (where was this movie actually made?)\n",
    "   - Language (is this actually in English?)\n",
    "4. Provide your response as a JSON object with only the corrected features\n",
    "5. If all features are correct, return: {{\"status\": \"all_correct\"}}\n",
    "6. For corrections, include a brief but clear reason\n",
    "\n",
    "**Response Format:**\n",
    "```json\n",
    "{{\n",
    "  \"corrections\": {{\n",
    "    \"feature_name\": {{\n",
    "      \"old_value\": false,\n",
    "      \"new_value\": true,\n",
    "      \"reason\": \"Brief explanation of why this is correct\"\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "Please provide your analysis:\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def validate_movie_features(movie_data, client, model=\"gpt-4o\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Send movie data to GPT-4o for feature validation\n",
    "    \"\"\"\n",
    "    prompt = create_validation_prompt(movie_data)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a movie expert who validates feature classifications for machine learning models. Always respond with valid JSON. Focus on accuracy and only correct features that are definitively wrong.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=2000  # Increased for all 34 features\n",
    "            )\n",
    "            \n",
    "            # Extract JSON from response\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Remove markdown code block markers if present\n",
    "            if content.startswith('```json'):\n",
    "                content = content[7:]\n",
    "            if content.endswith('```'):\n",
    "                content = content[:-3]\n",
    "            \n",
    "            # Parse JSON response\n",
    "            result = json.loads(content)\n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error for {movie_data['title']} (attempt {attempt + 1}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\"error\": f\"JSON decode failed after {max_retries} attempts\"}\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"API error for {movie_data['title']} (attempt {attempt + 1}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\"error\": f\"API call failed after {max_retries} attempts: {str(e)}\"}\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return {\"error\": \"Max retries exceeded\"}\n",
    "\n",
    "print(\"Validation functions defined with ALL 34 specified features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Test Validation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized successfully\n",
      "\n",
      "Testing validation system with: The Super Mario Bros. Movie (2023)\n",
      "API error for The Super Mario Bros. Movie (attempt 1): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "API error for The Super Mario Bros. Movie (attempt 2): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "API error for The Super Mario Bros. Movie (attempt 3): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "Validation result:\n",
      "{\n",
      "  \"error\": \"API call failed after 3 attempts: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "try:\n",
    "    client = openai.OpenAI()\n",
    "    print(\"OpenAI client initialized successfully\")\n",
    "    \n",
    "    # Test with a sample movie\n",
    "    test_movie = df[df['title'].str.contains('Mario', case=False, na=False)].iloc[0] if len(df[df['title'].str.contains('Mario', case=False, na=False)]) > 0 else df.iloc[0]\n",
    "    \n",
    "    print(f\"\\nTesting validation system with: {test_movie['title']} ({test_movie['release_year']})\")\n",
    "    \n",
    "    # Run validation\n",
    "    result = validate_movie_features(test_movie, client)\n",
    "    \n",
    "    print(\"\\nValidation result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "    print(\"Please make sure you have set your OpenAI API key:\")\n",
    "    print(\"1. Set environment variable: export OPENAI_API_KEY='your-key-here'\")\n",
    "    print(\"2. Or uncomment and set the api_key in the first cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Batch Validation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_corrections(df, corrections_log):\n",
    "    \"\"\"\n",
    "    Apply all collected corrections to the dataframe\n",
    "    \"\"\"\n",
    "    corrected_df = df.copy()\n",
    "    total_corrections = 0\n",
    "    \n",
    "    for idx, corrections in corrections_log.items():\n",
    "        if 'corrections' in corrections:\n",
    "            for feature, correction_info in corrections['corrections'].items():\n",
    "                old_value = correction_info['old_value']\n",
    "                new_value = correction_info['new_value']\n",
    "                reason = correction_info['reason']\n",
    "                \n",
    "                # Apply correction\n",
    "                corrected_df.at[idx, feature] = new_value\n",
    "                total_corrections += 1\n",
    "                \n",
    "                print(f\"Row {idx} ({corrected_df.at[idx, 'title']}): {feature} {old_value} → {new_value} ({reason})\")\n",
    "    \n",
    "    print(f\"\\nTotal corrections applied: {total_corrections}\")\n",
    "    return corrected_df\n",
    "\n",
    "def validate_dataset_subset(df, start_idx=0, end_idx=None, save_progress=True):\n",
    "    \"\"\"\n",
    "    Validate a subset of the dataset\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(df)\n",
    "    \n",
    "    subset = df.iloc[start_idx:end_idx]\n",
    "    corrections_log = {}\n",
    "    errors_log = {}\n",
    "    \n",
    "    print(f\"Validating movies {start_idx} to {end_idx-1} ({len(subset)} movies)\")\n",
    "    \n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize OpenAI client: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    for idx, row in tqdm(subset.iterrows(), total=len(subset), desc=\"Validating movies\"):\n",
    "        try:\n",
    "            # Validate movie features\n",
    "            result = validate_movie_features(row, client)\n",
    "            \n",
    "            # Store result\n",
    "            if 'error' in result:\n",
    "                errors_log[idx] = result\n",
    "            else:\n",
    "                corrections_log[idx] = result\n",
    "            \n",
    "            # Rate limiting - wait between API calls\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # Save progress every 10 movies\n",
    "            if save_progress and (idx - start_idx) % 10 == 9:\n",
    "                progress_file = f'../data/validation_progress_{start_idx}_{end_idx}.json'\n",
    "                with open(progress_file, 'w') as f:\n",
    "                    json.dump({\n",
    "                        'corrections': corrections_log,\n",
    "                        'errors': errors_log,\n",
    "                        'last_processed': idx\n",
    "                    }, f, indent=2)\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nValidation interrupted at row {idx}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for row {idx}: {e}\")\n",
    "            errors_log[idx] = {\"error\": str(e)}\n",
    "    \n",
    "    return corrections_log, errors_log, subset\n",
    "\n",
    "print(\"Batch validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Select Movies for Validation\n",
    "\n",
    "Let's prioritize validation for movies that are most likely to have errors, especially 2026 movies and IP-related films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritize movies for validation\n",
    "print(\"Selecting movies for validation...\")\n",
    "\n",
    "# High priority: 2026 movies (most likely to have errors)\n",
    "movies_2026 = df[df['release_year'] == 2026].copy()\n",
    "print(f\"2026 movies: {len(movies_2026)}\")\n",
    "\n",
    "# Medium priority: Recent movies (2024-2025) with IP/adaptation flags\n",
    "recent_ip_movies = df[\n",
    "    (df['release_year'].isin([2024, 2025])) & \n",
    "    (df['is_ip_movie'] == 1)\n",
    "].copy()\n",
    "print(f\"Recent IP movies (2024-2025): {len(recent_ip_movies)}\")\n",
    "\n",
    "# Sample of other movies for general validation\n",
    "other_movies = df[\n",
    "    (~df.index.isin(movies_2026.index)) & \n",
    "    (~df.index.isin(recent_ip_movies.index))\n",
    "].sample(n=min(50, len(df) - len(movies_2026) - len(recent_ip_movies)), random_state=42)\n",
    "print(f\"Sample of other movies: {len(other_movies)}\")\n",
    "\n",
    "# Combine prioritized datasets\n",
    "validation_subset = pd.concat([movies_2026, recent_ip_movies, other_movies]).reset_index(drop=True)\n",
    "print(f\"\\nTotal movies selected for validation: {len(validation_subset)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of movies to validate:\")\n",
    "display(validation_subset[['title', 'release_year', 'is_ip_movie', 'is_adaptation', 'is_marvel', 'is_dc']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Run Validation (Uncomment to Execute)\n",
    "\n",
    "**Warning**: This will make API calls to OpenAI. Make sure you have:\n",
    "1. Set your OpenAI API key\n",
    "2. Sufficient API credits\n",
    "3. Are ready to process the selected movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to run the validation\n",
    "# This will make API calls to OpenAI\n",
    "\n",
    "# print(\"Starting validation process...\")\n",
    "# print(\"This may take several minutes depending on the number of movies.\")\n",
    "# print(f\"Estimated cost: ~${len(validation_subset) * 0.01:.2f} (rough estimate)\")\n",
    "# \n",
    "# # Run validation on the prioritized subset\n",
    "# corrections_log, errors_log, validated_subset = validate_dataset_subset(\n",
    "#     validation_subset, \n",
    "#     start_idx=0, \n",
    "#     end_idx=len(validation_subset)\n",
    "# )\n",
    "# \n",
    "# # Display results\n",
    "# if corrections_log is not None:\n",
    "#     print(f\"\\nValidation completed!\")\n",
    "#     print(f\"Movies processed: {len(validated_subset)}\")\n",
    "#     print(f\"Movies with corrections: {len([c for c in corrections_log.values() if 'corrections' in c])}\")\n",
    "#     print(f\"Errors encountered: {len(errors_log)}\")\n",
    "#     \n",
    "#     # Save validation results\n",
    "#     results_file = '../data/llm_validation_results.json'\n",
    "#     with open(results_file, 'w') as f:\n",
    "#         json.dump({\n",
    "#             'corrections': corrections_log,\n",
    "#             'errors': errors_log,\n",
    "#             'validation_metadata': {\n",
    "#                 'total_movies': len(validated_subset),\n",
    "#                 'validation_date': pd.Timestamp.now().isoformat(),\n",
    "#                 'model_used': 'gpt-4o'\n",
    "#             }\n",
    "#         }, f, indent=2)\n",
    "#     \n",
    "#     print(f\"Results saved to: {results_file}\")\n",
    "# else:\n",
    "#     print(\"Validation failed to initialize\")\n",
    "\n",
    "print(\"Validation code ready (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Apply Corrections and Rebuild Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and apply validation results (uncomment when you have results)\n",
    "\n",
    "# try:\n",
    "#     # Load validation results\n",
    "#     with open('../data/llm_validation_results.json', 'r') as f:\n",
    "#         validation_results = json.load(f)\n",
    "#     \n",
    "#     corrections_log = validation_results['corrections']\n",
    "#     errors_log = validation_results['errors']\n",
    "#     \n",
    "#     print(f\"Loaded validation results:\")\n",
    "#     print(f\"- Movies with corrections: {len([c for c in corrections_log.values() if 'corrections' in c])}\")\n",
    "#     print(f\"- Errors: {len(errors_log)}\")\n",
    "#     \n",
    "#     # Apply corrections to the full dataset\n",
    "#     print(\"\\nApplying corrections to dataset...\")\n",
    "#     corrected_df = apply_corrections(df, corrections_log)\n",
    "#     \n",
    "#     # Save corrected dataset\n",
    "#     corrected_path = '../data/dataset_domestic_processed_llm_validated.csv'\n",
    "#     corrected_df.to_csv(corrected_path, index=False)\n",
    "#     print(f\"\\nCorrected dataset saved to: {corrected_path}\")\n",
    "#     \n",
    "#     # Generate validation report\n",
    "#     print(\"\\n=== VALIDATION REPORT ===\")\n",
    "#     \n",
    "#     # Count corrections by feature\n",
    "#     feature_corrections = {}\n",
    "#     for idx, corrections in corrections_log.items():\n",
    "#         if 'corrections' in corrections:\n",
    "#             for feature in corrections['corrections'].keys():\n",
    "#                 feature_corrections[feature] = feature_corrections.get(feature, 0) + 1\n",
    "#     \n",
    "#     print(\"\\nMost frequently corrected features:\")\n",
    "#     for feature, count in sorted(feature_corrections.items(), key=lambda x: x[1], reverse=True):\n",
    "#         print(f\"  {feature}: {count} corrections\")\n",
    "#     \n",
    "#     # Analyze improvement in key features\n",
    "#     key_features = ['is_ip_movie', 'is_adaptation', 'is_marvel', 'is_dc', 'is_superhero', 'is_sequel']\n",
    "#     \n",
    "#     print(\"\\nFeature accuracy improvements:\")\n",
    "#     for feature in key_features:\n",
    "#         if feature in corrected_df.columns:\n",
    "#             original_count = df[feature].sum()\n",
    "#             corrected_count = corrected_df[feature].sum()\n",
    "#             change = corrected_count - original_count\n",
    "#             print(f\"  {feature}: {original_count} → {corrected_count} ({change:+d})\")\n",
    "#     \n",
    "# except FileNotFoundError:\n",
    "#     print(\"No validation results found. Run validation first.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading validation results: {e}\")\n",
    "\n",
    "print(\"Correction application code ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides a complete system for validating and correcting movie features using GPT-4o. To use it:\n",
    "\n",
    "1. **Set up API access**: Add your OpenAI API key\n",
    "2. **Test the system**: Run the test validation to ensure everything works\n",
    "3. **Run validation**: Uncomment the validation code to process your selected movies\n",
    "4. **Apply corrections**: Use the results to generate a corrected dataset\n",
    "5. **Rebuild features**: Use the corrected dataset for model training\n",
    "\n",
    "The system prioritizes:\n",
    "- 2026 movies (most likely to have errors)\n",
    "- Recent IP movies (2024-2025)\n",
    "- A random sample of other movies for general validation\n",
    "\n",
    "Key features validated:\n",
    "- IP movie classification\n",
    "- Adaptation detection\n",
    "- Franchise identification (Marvel, DC, Star Wars, etc.)\n",
    "- Sequel detection\n",
    "- Studio classification\n",
    "- Superhero movie identification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "box_office",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
